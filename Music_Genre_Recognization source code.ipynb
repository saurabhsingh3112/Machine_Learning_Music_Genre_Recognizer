{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f1e72e6-9dc7-456b-89bb-fc731d654797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "58565a54-251b-427a-abe5-7ac293131cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, duration=30)\n",
    "        chroma_stft_mean = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "        mfccs_mean = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13))\n",
    "        spectral_centroid_mean = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "        spectral_rolloff_mean = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "        spectral_contrast_mean = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))\n",
    "        return chroma_stft_mean, mfccs_mean, spectral_centroid_mean, spectral_rolloff_mean, spectral_contrast_mean\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file_path}. Skipping.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a8191a4a-b0ce-4174-bf5e-b72663fd865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_parallel(file_paths):\n",
    "    X = []\n",
    "    processed_files = []\n",
    "    for file_path in file_paths:\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            processed_files.append(file_path)\n",
    "    return np.array(X), processed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "50f63bd8-26f1-4010-b298-d1cdc759cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "data_directory = r\"D:\\Machine Learning Project\\DATA_SETS\\Data\\genres\"\n",
    "audio_files = []\n",
    "# Load music files from dataset\n",
    "for genre_label in os.listdir(data_directory):\n",
    "    genre_path = os.path.join(data_directory, genre_label)\n",
    "    audio_files.extend([os.path.join(genre_path, file_name) for file_name in os.listdir(genre_path) if file_name.endswith('.wav')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "275d5528-1ba0-4053-b96e-1c2c7867601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, processed_files = extract_features_parallel(audio_files)\n",
    "# Load genre labels\n",
    "y = [os.path.basename(os.path.dirname(file_path)) for file_path in processed_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c620750-f864-420c-a322-3fe30107d403",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Encode genre labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "76749764-08f2-487d-8cde-0e73ab3f67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a36981e1-61cb-41a0-b314-85f9f6ac488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca689048-5ccf-4b67-af5c-e6622c7a06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4f235081-7993-4ba6-a2a9-d77130a115ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 0.3222222328186035\n",
      "Epoch 2, Accuracy: 0.35555556416511536\n",
      "Epoch 3, Accuracy: 0.3222222328186035\n",
      "Epoch 4, Accuracy: 0.3499999940395355\n",
      "Epoch 5, Accuracy: 0.3611111044883728\n",
      "Epoch 6, Accuracy: 0.3333333432674408\n",
      "Epoch 7, Accuracy: 0.31111112236976624\n",
      "Epoch 8, Accuracy: 0.35555556416511536\n",
      "Epoch 9, Accuracy: 0.3333333432674408\n",
      "Epoch 10, Accuracy: 0.3222222328186035\n",
      "Epoch 11, Accuracy: 0.3222222328186035\n",
      "Epoch 12, Accuracy: 0.33888888359069824\n",
      "Epoch 13, Accuracy: 0.33888888359069824\n",
      "Epoch 14, Accuracy: 0.35555556416511536\n",
      "Epoch 15, Accuracy: 0.3333333432674408\n",
      "Epoch 16, Accuracy: 0.35555556416511536\n",
      "Epoch 17, Accuracy: 0.33888888359069824\n",
      "Epoch 18, Accuracy: 0.35555556416511536\n",
      "Epoch 19, Accuracy: 0.3222222328186035\n",
      "Epoch 20, Accuracy: 0.3499999940395355\n",
      "Epoch 21, Accuracy: 0.3055555522441864\n",
      "Epoch 22, Accuracy: 0.3611111044883728\n",
      "Epoch 23, Accuracy: 0.33888888359069824\n",
      "Epoch 24, Accuracy: 0.33888888359069824\n",
      "Epoch 25, Accuracy: 0.3722222149372101\n",
      "Epoch 26, Accuracy: 0.3499999940395355\n",
      "Epoch 27, Accuracy: 0.31111112236976624\n",
      "Epoch 28, Accuracy: 0.3444444537162781\n",
      "Epoch 29, Accuracy: 0.3611111044883728\n",
      "Epoch 30, Accuracy: 0.33888888359069824\n",
      "Epoch 31, Accuracy: 0.35555556416511536\n",
      "Epoch 32, Accuracy: 0.3444444537162781\n",
      "Epoch 33, Accuracy: 0.3166666626930237\n",
      "Epoch 34, Accuracy: 0.3444444537162781\n",
      "Epoch 35, Accuracy: 0.3444444537162781\n",
      "Epoch 36, Accuracy: 0.3333333432674408\n",
      "Epoch 37, Accuracy: 0.33888888359069824\n",
      "Epoch 38, Accuracy: 0.36666667461395264\n",
      "Epoch 39, Accuracy: 0.3333333432674408\n",
      "Epoch 40, Accuracy: 0.2888889014720917\n",
      "Epoch 41, Accuracy: 0.3333333432674408\n",
      "Epoch 42, Accuracy: 0.3444444537162781\n",
      "Epoch 43, Accuracy: 0.33888888359069824\n",
      "Epoch 44, Accuracy: 0.31111112236976624\n",
      "Epoch 45, Accuracy: 0.35555556416511536\n",
      "Epoch 46, Accuracy: 0.3777777850627899\n",
      "Epoch 47, Accuracy: 0.3333333432674408\n",
      "Epoch 48, Accuracy: 0.3444444537162781\n",
      "Epoch 49, Accuracy: 0.3611111044883728\n",
      "Epoch 50, Accuracy: 0.2888889014720917\n"
     ]
    }
   ],
   "source": [
    "# Train the model with multiple epochs\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    print(f\"Epoch {epoch + 1}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "def0694f-5b22-4e4c-9f07-01cc1bde7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"music_genre_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "05be09d7-e255-4ea4-a52b-144147c09203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for prediction on new audio files\n",
    "loaded_model = keras.models.load_model(\"music_genre_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9feb880b-b033-4e2e-872b-f797021a7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on new audio files\n",
    "new_audio_files = [r\"C:\\Users\\saura\\Downloads\\Tum Hi Ho.wav\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "71f8149b-daf7-4205-b57c-eea80c17d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, processed_files = extract_features_parallel(new_audio_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "903cbb97-bd33-4f7c-9fd4-e5fcb2873bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new audio files\n",
    "y_new_pred = loaded_model.predict(X_new)\n",
    "y_new_pred_genre = label_encoder.inverse_transform(np.argmax(y_new_pred, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1c8985b9-5beb-4813-b6b8-8a767a0f74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\saura\\Downloads\\Tum Hi Ho.wav --> Predicted Genre: jazz\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted genre for each new audio file\n",
    "for file_path, genre in zip(new_audio_files, y_new_pred_genre):\n",
    "    print(f\"File: {file_path} --> Predicted Genre: {genre}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
